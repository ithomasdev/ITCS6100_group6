{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29dc6839-6055-46f1-b060-607973459595",
   "metadata": {},
   "source": [
    "# Deliverable 3 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ce69f-ec67-4116-b6f6-a44c19d24756",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "10caf08d-e59d-478e-bd4c-8c2243604237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813450d6-f75a-48bb-9e3e-630f8b7ac3d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d54b6-8c8f-4684-b3f2-341a0ed6cdc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "45333b99-57a7-4131-83c3-6ac600ff7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe from csv\n",
    "df = pd.read_csv(\"./data/athletes.csv\")\n",
    "\n",
    "# drop unused columns for optimization\n",
    "df = df.drop(['athlete_id', 'name', 'region', 'team', 'affiliate', 'eat', 'train', 'background', 'experience', 'schedule', 'howlong'], axis=1)\n",
    "\n",
    "# drop bad values in gender column\n",
    "df = df.dropna(subset=['gender'])\n",
    "df = df[df.gender != '--']\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "\n",
    "# create an imputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# imputting median values for each NaN value\n",
    "clean_data = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# remove corrupt values\n",
    "clean_data = clean_data[clean_data['height'] <= 202]\n",
    "clean_data = clean_data[clean_data['weight'] <= 210] \n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(clean_data), columns=clean_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1d4d8-6e31-488e-b710-20fbce718880",
   "metadata": {},
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d45d29c3-e5b8-43c9-aade-7fcacd0c5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two random halves\n",
    "half1 = scaled_data.sample(frac=0.5, random_state=0)\n",
    "half2 = scaled_data.drop(half1.index)\n",
    "\n",
    "# Split each half into training and test sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(half1[['gender', 'weight']], half1[['fran', 'helen', 'grace', 'filthy50', 'fgonebad', 'run400', 'run5k']], test_size=0.2, random_state=0)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(half2[['gender', 'weight']], half2[['fran', 'helen', 'grace', 'filthy50', 'fgonebad', 'run400', 'run5k']], test_size=0.2, random_state=0)\n",
    "\n",
    "# Concatenate the training and test sets from each half\n",
    "X_train = pd.concat([X_train1, X_train2])\n",
    "X_test = pd.concat([X_test1, X_test2])\n",
    "y_train = pd.concat([y_train1, y_train2])\n",
    "y_test = pd.concat([y_test1, y_test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b1b04-bb3c-47dc-9297-478562596c51",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "5fa3c2a6-30b2-4054-bd62-e394a321fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.025272263296622088\n",
      "R2 score: -0.05673835287324141\n"
     ]
    }
   ],
   "source": [
    "# Create a ridge regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Set the hyperparameters to tune\n",
    "parameters = {'alpha': [0.1, 1, 10, 100]}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid = GridSearchCV(ridge, parameters, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Train the model on the training set with the best hyperparameters\n",
    "best_ridge = grid.best_estimator_\n",
    "best_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326637aa-6b34-4663-a81c-c6b176449819",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34936e57-ca95-43b0-b62a-a9355514c750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
